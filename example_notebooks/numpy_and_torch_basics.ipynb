{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ranges of Values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a 1D Numpy array containing the 32-bit floating point values from 0 to 11\n",
    "x_numpy = np.arange(12, dtype=np.float32)\n",
    "# Create a 1D Torch tensor containing the 32-bit floating point values from 0 to 11\n",
    "x_torch = torch.arange(12, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(x_numpy), type(x_torch))\n",
    "print(x_numpy.shape, x_torch.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ones and Zeros"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Containing only ones with same data types and size as before\n",
    "y_numpy_ones = np.ones_like(x_numpy)\n",
    "y_torch_ones = torch.ones_like(x_torch)\n",
    "\n",
    "# Containing only zeros with same data types and size as before\n",
    "z_numpy_zeros = np.zeros_like(y_numpy_ones)\n",
    "z_torch_zeros = torch.zeros_like(y_torch_ones)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y_numpy_ones.sum(), y_torch_ones.sum())\n",
    "print(z_numpy_zeros.sum(), z_torch_zeros.sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count the number of elements in the tensors/array. This is a case where the two libraries differ a bit\n",
    "print(y_torch_ones.numel())\n",
    "print(y_numpy_ones.size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's look at creating some random values. Let's say we want a 2D tensor of shape 5x5 with random 16-bit floating points values samples from a Gaussian distribution\n",
    "r_numpy = np.random.randn(5, 5).astype(np.float16)\n",
    "r_torch = torch.randn((5,5), dtype=torch.float16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reshaping Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_numpy.reshape(3,4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_torch.reshape(3,4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we can also ask Numpy/Torch to automatically infer one of the dimensions\n",
    "x_numpy.reshape(3, -1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_torch.reshape(-1, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Indexing and Slicing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's create tensors of shape 3,4,5, containing random integers between 0 and 10\n",
    "# The indexing and slicing mechanisms are the same for Numpy and Torch, so we will just use Torch for now\n",
    "t_torch = torch.randint(0, 10, (3,4,5), dtype=torch.int8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grab just the first 4x5 tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_torch[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grab the last row in the last 4x5 tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_torch[-1][-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Equivalent way of doing this with slicing\n",
    "t_torch[-1,-1,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grab just the first 2 columns in the first row of the second 4x5 tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_torch[1,0,0:2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grab the element in the 2nd row and 3rd column of the third 4x5 tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this is equivalent to, but faster than t_torch[2][1][2]\n",
    "t_torch[2,1,2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assigning Values\n",
    "### You can rewrite values of a tensor using the same indexing and slicing mechanisms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_tensor = torch.tensor([4, 4, 3, 3, 2, 2, 1, 1, 0], dtype=torch.float16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_tensor[0] = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_tensor[-2:] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_other_tensor = torch.tensor([[1, 2, 3], [3, 2, 1], [0, 1, 0], [0, 0, 0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_other_tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_other_tensor[1, 0:2] = torch.tensor([8, 9])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_other_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combining Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.int8)\n",
    "tensor2 = torch.tensor([[7, 8 ,9], [10, 11, 12]], dtype=torch.int8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we can concatenate tensors together. To do so, you tell Torch on which axis you want to concatenate\n",
    "# let's first concatenate along rows\n",
    "tensor3 = torch.cat((tensor1, tensor2), dim=0)\n",
    "tensor3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now let's concatenate along columns\n",
    "tensor4 = torch.cat((tensor1, tensor2), dim=1)\n",
    "tensor4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unary Operators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([0, 2, 4, 6, 8], dtype=torch.float64)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# absolute value\n",
    "x.abs()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sqrt\n",
    "x.sqrt()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# e^x\n",
    "x.exp()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Operators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([0, 2, 4, 6, 8], dtype=torch.float64)\n",
    "y = torch.tensor([1, 3, 2, 1, 4], dtype=torch.float64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# elementwise addition of two vectors\n",
    "x + y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# elementwise subtraction of two vectors\n",
    "x - y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# elementwise multiplication of two vectors\n",
    "x * y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# elementwise division of two vectors\n",
    "x / y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# elementwise exponentiation of two vectors\n",
    "x ** y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Broadcasting\n",
    "\n",
    "### Elementwise vector operations can sometimes be applied to tensors of differing shape, using broadcasting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([[0], [1], [2]])\n",
    "y = torch.tensor([[0, 1]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x,y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In the following operation, x will expand from 1 to 2 columns to result in a 3x2 tensor, copying column 0 of x into column 1. Likewise, y will expand from a 1x2 tensor to a 3x2 tensor by copying row 0 twice. The expanded forms of x and y will then be added"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x + y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Memory Allocation\n",
    "\n",
    "### Operations on tensors can create additional memory overhead in some cases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "x = torch.tensor([0,1,2])\n",
    "y = torch.tensor([0,1,2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "(13047931792, 13047935792)"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id() gets the memory address\n",
    "id(x), id(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "y = x + y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "13047990608"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### As we can see, reassigning y to x + y ends up storing the result in a different memory location."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "(13047927712, 13047923792)"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0,1,2])\n",
    "y = torch.tensor([0,1,2])\n",
    "id(x), id(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "y += x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "13047923792"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using y += x, which is also equivalent to y[:] = y + x, perhaps the operation in-place"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Numpy/Torch Conversions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert a torch tensor to a Numpy array\n",
    "y_numpy = y.numpy()\n",
    "type(y_numpy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert a Numpy array to a Torch tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_numpy = np.arange(3)\n",
    "x_torch = torch.from_numpy(x_numpy)\n",
    "type(x_torch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor Operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = torch.ones((3,4)) * 2\n",
    "B = torch.ones((3,4)) * 3\n",
    "A,B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hadamard Product"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A * B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reduction Operations\n",
    "### These operations reduce the order of tensors along one or more axes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reduction of nth order tensor to 1st order tensor\n",
    "# total sum and total mean\n",
    "print(A.sum(), A.mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduction of nth order tensor to n-1'th order tensor\n",
    "# row sum and row mean\n",
    "A.sum(axis=0), A.mean(axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# column sum and column mean\n",
    "A.sum(axis=1), A.mean(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Non-reducing Sum or Mean\n",
    "We can set keepdims=True to not get rid of the reduced axis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reducing sum\n",
    "C = A.sum(axis=1)\n",
    "print(C, C.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# non-reducing sum\n",
    "C = A.sum(axis=1, keepdim=True)\n",
    "print(C, C.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Norms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([0, 4, 1, 3, 8], dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L2 Norm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.norm()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L1 Norm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.abs().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Euclidean distance between two vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([0, 4, 1, 3, 8], dtype=torch.float32)\n",
    "y = torch.tensor([-8, 5, 2, -1, 4], dtype=torch.float32)\n",
    "\n",
    "torch.norm(x-y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vector Dot Product"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "v = torch.tensor([4, 1, -5], dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u@v"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the following is identical to above\n",
    "torch.dot(u, v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matrix Vector Product\n",
    "\n",
    "## Example of dimensionality reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 0, 1], [0, 1, -1]], dtype=torch.float32)\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "A.shape, x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A@x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the following is identical to above\n",
    "torch.mv(A, x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example of 90 degree rotation operation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = torch.tensor([[0, -1], [1, 0]], dtype=torch.float32)\n",
    "x = torch.tensor([1, 0], dtype=torch.float32)\n",
    "A.shape, x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A@x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matrix Matrix Product"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "B = torch.tensor([[1, 1, 1, 1],[2, 2, 2, 2],[3, 3, 3, 3]], dtype=torch.float32)\n",
    "A.shape, B.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A@B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the follow is identical to above\n",
    "torch.mm(A, B)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Autograd\n",
    "\n",
    "## Let's First Consider a Scalar-valued Function\n",
    "\n",
    "### $y = 2 \\mathbf{x}^\\top \\mathbf{x}$\n",
    "\n",
    "Let $\\mathbf{x}$ be a column vector in $\\mathbb{R}^n$. The function is defined as:\n",
    "$$\n",
    "y = 2 \\mathbf{x}^\\top \\mathbf{x}\n",
    "$$\n",
    "This is equivalent to:\n",
    "$$\n",
    "y = 2 \\sum_{i=1}^n x_i^2\n",
    "$$\n",
    "\n",
    "In PyTorch, we can compute this function and its gradient using **Autograd**.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define x as a column vector with requires_grad=True to enable gradient computation\n",
    "x = torch.tensor([[0.0], [1.0], [2.0], [3.0]], requires_grad=True)\n",
    "\n",
    "# Define the function y = 2 * x^T * x\n",
    "y = 2 * torch.matmul(x.T, x)\n",
    "\n",
    "# Perform backpropagation\n",
    "y.backward()\n",
    "\n",
    "# Display the computed gradient\n",
    "print(\"Gradient of y with respect to x:\")\n",
    "print(x.grad)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.grad.zero_()  # Reset the gradient\n",
    "y = x.sum()  # Redefine a different function\n",
    "y.backward()  # backpropagate\n",
    "x.grad  # get the gradient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's Now Consider a Vector-valued Function\n",
    "\n",
    "Let:\n",
    "$$\n",
    "\\mathbf{u}(\\mathbf{x}) =\n",
    "\\begin{bmatrix}\n",
    "u_1(\\mathbf{x}) \\\\\n",
    "u_2(\\mathbf{x})\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_1^2 + x_2 \\\\\n",
    "\\sin(x_1) + x_2^3\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The Jacobian matrix is:\n",
    "$$\n",
    "J_{\\mathbf{u}}(\\mathbf{x}) =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial u_1}{\\partial x_1} & \\frac{\\partial u_1}{\\partial x_2} \\\\\n",
    "\\frac{\\partial u_2}{\\partial x_1} & \\frac{\\partial u_2}{\\partial x_2}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2x_1 & 1 \\\\\n",
    "\\cos(x_1) & 3x_2^2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "At\n",
    "\n",
    "$$\\( \\mathbf{x} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\)$$we have\n",
    "$$\n",
    "J_{\\mathbf{u}}(\\mathbf{x}) =\n",
    "\\begin{bmatrix}\n",
    "2(1) & 1 \\\\\n",
    "\\cos(1) & 3(2)^2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "\\cos(1) & 12\n",
    "\\end{bmatrix}.\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define input vector x with gradients enabled\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)  # x = [x1, x2]\n",
    "\n",
    "# Define the vector-valued function u(x)\n",
    "u1 = x[0]**2 + x[1]  # u1 = x1^2 + x2\n",
    "u2 = torch.sin(x[0]) + x[1]**3  # u2 = sin(x1) + x2^3\n",
    "u = torch.stack([u1, u2])  # Stack outputs into a vector u = [u1, u2]\n",
    "\n",
    "# Compute the Jacobian of u(x) with respect to x before computing the gradient of y\n",
    "jacobian = []\n",
    "for i in range(len(u)):\n",
    "    grad_u = torch.autograd.grad(u[i], x, retain_graph=True, create_graph=True)[0]\n",
    "    jacobian.append(grad_u)\n",
    "jacobian = torch.stack(jacobian)\n",
    "\n",
    "print(\"Jacobian of u with respect to x:\")\n",
    "print(jacobian)\n",
    "\n",
    "# Define a scalar function y(u)\n",
    "y = 2 * u[0] + 3 * u[1]  # y = 2*u1 + 3*u2\n",
    "\n",
    "# Perform backpropagation\n",
    "y.backward(retain_graph=True)  # Retain graph for subsequent operations\n",
    "\n",
    "# Print the gradient of y with respect to x\n",
    "print(\"Gradient of y with respect to x:\", x.grad)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
